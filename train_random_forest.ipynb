{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31424d31",
   "metadata": {},
   "source": [
    "# YTSG Random Forest\n",
    "\n",
    "This script trains a random forest algorithm against the classified page data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3398c4b-5e65-43f3-a193-6051f0934199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and set up project\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf43b2e-bd4c-4ce5-9e47-2804f1ac4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data and define feature columns\n",
    "conn = sqlite3.connect('ytsg-dataset.db')\n",
    "query = \"\"\"SELECT \n",
    "    * ,\n",
    "    (LENGTH(categories) - LENGTH(REPLACE(categories, \"||\", \"|\")) +1) AS category_count \n",
    "FROM manual_page_classifications LIMIT 5000\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "feature_columns = [\n",
    "    'total_length',\n",
    "    'file_page',\n",
    "    'target_words_in_section_titles',\n",
    "    'category_count',\n",
    "    #'section_count',\n",
    "    'image_count',\n",
    "    #'audio_count'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b162eb",
   "metadata": {},
   "source": [
    "## Try all combinations of feature columns\n",
    "This is a time-consuming process that outputs the top 5 most accurate combinations of feature columns.\n",
    "The function is wrapped in a False if to avoid the long run time after features have been identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Split up training and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df, df['rating_class'], test_size=0.30, random_state=11)\n",
    "\n",
    "    # Generate all possible combinations of feature columns\n",
    "    all_combinations = []\n",
    "    for r in range(1, len(feature_columns) + 1):\n",
    "        combinations_object = itertools.combinations(feature_columns, r)\n",
    "        combinations_list = list(combinations_object)\n",
    "        all_combinations += combinations_list\n",
    "\n",
    "    results = {}\n",
    "    # Train a model for each combination and calculate the accuracy score\n",
    "    for combination in all_combinations:\n",
    "        x_train_combination = x_train[list(combination)]\n",
    "        x_test_combination = x_test[list(combination)]\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=11)\n",
    "        rf.fit(x_train_combination, y_train)\n",
    "\n",
    "        y_pred = rf.predict(x_test_combination)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        # Store the results in the dictionary\n",
    "        results[combination] = accuracy\n",
    "\n",
    "    # Sort the results by accuracy score\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the top 5 combinations and their accuracy scores\n",
    "    for combination, accuracy in sorted_results[:5]:\n",
    "        print(f'Feature Combination: {combination}, Accuracy: {accuracy}')\n",
    "        \n",
    "\n",
    "        #print(f'Feature Combination: {combination}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3805cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values\n",
    "# scaler = MinMaxScaler()\n",
    "# for column in feature_columns:\n",
    "#     df[column] = scaler.fit_transform(df[[column]])\n",
    "# print(df[feature_columns].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training data\n",
    "# Split up features (x) and target (y)\n",
    "x = df[feature_columns]\n",
    "y = df['rating_class']\n",
    "\n",
    "# Split up training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.60, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out the data and fit a random forest against it\n",
    "\n",
    "# Train the model\n",
    "print('Training Model')\n",
    "rf = RandomForestClassifier(random_state=11)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Predict test values\n",
    "print('Predict test set values')\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "# Check accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cbdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Define the hyperparameters to tune\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "\n",
    "    # Fit GridSearchCV to the data\n",
    "    print('Searching for optimal hyperparameters')\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Print the best parameters and the best score\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "    # Use the best model to make predictions on the test set\n",
    "    y_pred = grid_search.predict(x_test)\n",
    "\n",
    "    # Check accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Test Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb93cd9",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "labels = ['unusable', 'bad', 'fine', 'good', 'viral']\n",
    "#labels = ['viral', 'good', 'fine', 'bad', 'unusable']\n",
    "print(labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=labels)\n",
    "disp.plot()\n",
    "#plt.gca().set_ylim(len(labels)-0.5, -0.5)  # This line reverses the y-axis\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
